{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f931ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size M L XL XXL\n",
      "chest_width 41 43 46 48\n",
      "length 25 26.5 27 28.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "img = Image.open(\"s.png\")\n",
    "print(pytesseract.image_to_string(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad201f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_size(measurements, size_chart):\n",
    "    \"\"\"\n",
    "    measurements: dict with keys like chest_width, shoulder_width, shirt_length\n",
    "    size_chart: dict of sizes \n",
    "        { \n",
    "          \"M\": {\"chest_width\": 101.6, \"shoulder_width\": 41.91, \"shirt_length\": 73.66}, \n",
    "          ... \n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert body chest width → circumference (pit-to-pit × 2)\n",
    "    body_chest_circ = measurements.get(\"chest_width\", 0) * 2\n",
    "    body_shoulder = measurements.get(\"shoulder_width\", 0)\n",
    "    body_length = measurements.get(\"shirt_length\", 0)\n",
    "\n",
    "    best_size, best_score = None, float(\"inf\")\n",
    "\n",
    "    for size, values in size_chart.items():\n",
    "        # ✅ Size chart chest is already circumference → do NOT multiply by 2\n",
    "        chart_chest_circ = values[\"chest_width\"]\n",
    "        chart_shoulder = values[\"shoulder_width\"]\n",
    "        chart_length = values[\"shirt_length\"]\n",
    "\n",
    "        # Differences\n",
    "        diff_chest = abs(chart_chest_circ - body_chest_circ)\n",
    "        diff_shoulder = abs(chart_shoulder - body_shoulder)\n",
    "        diff_length = abs(chart_length - body_length)\n",
    "\n",
    "        # Weighted score (chest is most important)\n",
    "        score = (diff_chest * 0.6) + (diff_shoulder * 0.25) + (diff_length * 0.15)\n",
    "\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_size = size\n",
    "\n",
    "    # Out-of-range detection\n",
    "    # if best_size is None or body_chest_circ > max(v[\"chest_width\"] for v in size_chart.values()):\n",
    "    #     return \"Size larger than available chart\"\n",
    "    # if body_chest_circ < min(v[\"chest_width\"] for v in size_chart.values()):\n",
    "    #     return \"Size smaller than available chart\"\n",
    "\n",
    "    return best_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cde800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import torch\n",
    "from flask import Flask, request, jsonify\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_holistic = mp.solutions.holistic\n",
    "pose = mp_pose.Pose(model_complexity=2)  # Improved accuracy\n",
    "holistic = mp_holistic.Holistic()  # For refining pose\n",
    "\n",
    "KNOWN_OBJECT_WIDTH_CM = 21.0  # A4 paper width in cm\n",
    "FOCAL_LENGTH = 600  # Default focal length\n",
    "DEFAULT_HEIGHT_CM = 152.0  # Default height if not provided\n",
    "\n",
    "# Load depth estimation model\n",
    "def load_depth_model():\n",
    "    model = torch.hub.load(\"intel-isl/MiDaS\", \"MiDaS_small\")\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "depth_model = load_depth_model()\n",
    "\n",
    "def calibrate_focal_length(image, real_width_cm, detected_width_px):\n",
    "    \"\"\"Dynamically calibrates focal length using a known object.\"\"\"\n",
    "    return (detected_width_px * FOCAL_LENGTH) / real_width_cm if detected_width_px else FOCAL_LENGTH\n",
    "\n",
    "\n",
    "\n",
    "def detect_reference_object(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        focal_length = calibrate_focal_length(image, KNOWN_OBJECT_WIDTH_CM, w)\n",
    "        scale_factor = KNOWN_OBJECT_WIDTH_CM / w\n",
    "        return scale_factor, focal_length\n",
    "    return 0.05, FOCAL_LENGTH\n",
    "\n",
    "def estimate_depth(image):\n",
    "    \"\"\"Uses AI-based depth estimation to improve circumference calculations.\"\"\"\n",
    "    input_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0\n",
    "    input_tensor = torch.tensor(input_image, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n",
    "    \n",
    "    # Resize input to match MiDaS model input size\n",
    "    input_tensor = F.interpolate(input_tensor, size=(384, 384), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        depth_map = depth_model(input_tensor)\n",
    "    \n",
    "    return depth_map.squeeze().numpy()\n",
    "\n",
    "def calculate_distance_using_height(landmarks, image_height, user_height_cm):\n",
    "    \"\"\"Calculate distance using the user's known height.\"\"\"\n",
    "    top_head = landmarks[mp_pose.PoseLandmark.NOSE.value].y * image_height\n",
    "    bottom_foot = max(\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y,\n",
    "        landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y\n",
    "    ) * image_height\n",
    "    \n",
    "    person_height_px = abs(bottom_foot - top_head)\n",
    "    \n",
    "    # Using the formula: distance = (actual_height_cm * focal_length) / height_in_pixels\n",
    "    distance = (user_height_cm * FOCAL_LENGTH) / person_height_px\n",
    "    \n",
    "    # Calculate more accurate scale_factor based on known height\n",
    "    scale_factor = user_height_cm / person_height_px\n",
    "    \n",
    "    return distance, scale_factor\n",
    "        \n",
    "def get_body_depth_at_height(frame, height_px, center_x):\n",
    "    \"\"\"Scan horizontally at a specific height to find body depth (from side view).\"\"\"\n",
    "    # Convert to grayscale and apply threshold\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, thresh = cv2.threshold(blur, 50, 255, cv2.THRESH_BINARY)\n",
    "    if height_px >= frame.shape[0]:\n",
    "        height_px = frame.shape[0] - 1\n",
    "    horizontal_line = thresh[height_px, :]\n",
    "    center_x = int(center_x * frame.shape[1])\n",
    "    left_edge, right_edge = center_x, center_x\n",
    "    for i in range(center_x, 0, -1):\n",
    "        if horizontal_line[i] == 0:\n",
    "            left_edge = i\n",
    "            break\n",
    "    for i in range(center_x, len(horizontal_line)):\n",
    "        if horizontal_line[i] == 0:\n",
    "            right_edge = i\n",
    "            break\n",
    "    width_px = right_edge - left_edge\n",
    "    min_width = 0.1 * frame.shape[1]\n",
    "    if width_px < min_width:\n",
    "        width_px = min_width\n",
    "    return width_px\n",
    "\n",
    "def get_body_width_at_height(frame, height_px, center_x):\n",
    "    \"\"\"Scan horizontally at a specific height to find body edges.\"\"\"\n",
    "    # Convert to grayscale and apply threshold\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, thresh = cv2.threshold(blur, 50, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Ensure height_px is within image bounds\n",
    "    if height_px >= frame.shape[0]:\n",
    "        height_px = frame.shape[0] - 1\n",
    "    \n",
    "    # Get horizontal line at the specified height\n",
    "    horizontal_line = thresh[height_px, :]\n",
    "    \n",
    "    # Find left and right edges starting from center\n",
    "    center_x = int(center_x * frame.shape[1])\n",
    "    left_edge, right_edge = center_x, center_x\n",
    "    \n",
    "    # Scan from center to left\n",
    "    for i in range(center_x, 0, -1):\n",
    "        if horizontal_line[i] == 0:  # Found edge (black pixel)\n",
    "            left_edge = i\n",
    "            break\n",
    "    \n",
    "    # Scan from center to right\n",
    "    for i in range(center_x, len(horizontal_line)):\n",
    "        if horizontal_line[i] == 0:  # Found edge (black pixel)\n",
    "            right_edge = i\n",
    "            break\n",
    "            \n",
    "    width_px = right_edge - left_edge\n",
    "    \n",
    "    # If width is unreasonably small, apply a minimum width\n",
    "    min_width = 0.1 * frame.shape[1]  # Minimum width as 10% of image width\n",
    "    if width_px < min_width:\n",
    "        width_px = min_width\n",
    "        \n",
    "    return width_px\n",
    "\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "import re\n",
    "\n",
    "def extract_size_chart(size_chart_image_bytes):\n",
    "    \"\"\"Extracts size chart data from an image using OCR and returns a dict.\"\"\"\n",
    "    image = Image.open(io.BytesIO(size_chart_image_bytes))\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    size_chart = {}\n",
    "    lines = text.splitlines()\n",
    "    header = None\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if not header and re.search(r\"size\", line, re.I):\n",
    "            header = [h.strip().lower() for h in re.split(r\"\\s+\", line)]\n",
    "            continue\n",
    "        if header:\n",
    "            parts = re.split(r\"\\s+\", line)\n",
    "            if len(parts) >= 2:\n",
    "                size = parts[0].upper()\n",
    "                try:\n",
    "                    values = {header[i+1]: float(parts[i+1]) for i in range(len(parts)-1)}\n",
    "                    size_chart[size] = values\n",
    "                except Exception:\n",
    "                    continue\n",
    "    return size_chart\n",
    "\n",
    "def find_best_size(measurements, size_chart):\n",
    "    \"\"\"Finds the closest size from the size chart based on chest_width, shirt_lenght, shoulder_width.\"\"\"\n",
    "    if not size_chart:\n",
    "        return None\n",
    "    keys = [\"chest_width\", \"shirt_lenght\", \"shoulder_width\"]\n",
    "    best_size = None\n",
    "    best_score = float(\"inf\")\n",
    "    for size, values in size_chart.items():\n",
    "        score = 0\n",
    "        for key in keys:\n",
    "            if key in measurements and key in values:\n",
    "                score += abs(measurements.get(key, 0) - values[key])\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_size = size\n",
    "    return best_size\n",
    "\n",
    "\n",
    "def calculate_measurements(results, scale_factor, image_width, image_height, depth_map, frame=None, user_height_cm=None):\n",
    "    landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "    # If user's height is provided, use it to get a more accurate scale factor\n",
    "    if user_height_cm:\n",
    "        _, scale_factor = calculate_distance_using_height(landmarks, image_height, user_height_cm)\n",
    "\n",
    "    def pixel_to_cm(value):\n",
    "        return round(value * scale_factor, 2)\n",
    "    \n",
    "    def calculate_circumference(width_px, depth_ratio=1.0):\n",
    "        \"\"\"Estimate circumference using width and depth adjustment.\"\"\"\n",
    "        # Using a simplified elliptical approximation: C ≈ 2π * sqrt((a² + b²)/2)\n",
    "        # where a is half the width and b is estimated depth\n",
    "        width_cm = width_px * scale_factor\n",
    "        estimated_depth_cm = width_cm * depth_ratio * 0.7  # Depth is typically ~70% of width for torso\n",
    "        half_width = width_cm / 2\n",
    "        half_depth = estimated_depth_cm / 2\n",
    "        return round(2 * np.pi * np.sqrt((half_width**2 + half_depth**2) / 2), 2)\n",
    "\n",
    "    measurements = {}\n",
    "\n",
    "    # Shoulder Width\n",
    "    left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "    right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
    "    shoulder_width_px = abs(left_shoulder.x * image_width - right_shoulder.x * image_width)\n",
    "    \n",
    "    # Apply a slight correction factor for shoulders (they're usually detected well)\n",
    "    shoulder_correction = 1.1  # 10% wider\n",
    "    shoulder_width_px *= shoulder_correction\n",
    "    \n",
    "    measurements[\"shoulder_width\"] = pixel_to_cm(shoulder_width_px)\n",
    "\n",
    "    # Chest/Bust Measurement\n",
    "    chest_y_ratio = 0.15  # Approximately 15% down from shoulder to hip\n",
    "    chest_y = left_shoulder.y + (landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y - left_shoulder.y) * chest_y_ratio\n",
    "    \n",
    "    chest_correction = 1.15  # 15% wider than detected width\n",
    "    chest_width_px = abs((right_shoulder.x - left_shoulder.x) * image_width) * chest_correction\n",
    "    \n",
    "    if frame is not None:\n",
    "        chest_y_px = int(chest_y * image_height)\n",
    "        center_x = (left_shoulder.x + right_shoulder.x) / 2\n",
    "        detected_width = get_body_width_at_height(frame, chest_y_px, center_x)\n",
    "        if detected_width > 0:\n",
    "            chest_width_px = max(chest_width_px, detected_width)\n",
    "    \n",
    "    chest_depth_ratio = 1.0\n",
    "    if depth_map is not None:\n",
    "        chest_x = int(((left_shoulder.x + right_shoulder.x) / 2) * image_width)\n",
    "        chest_y_px = int(chest_y * image_height)\n",
    "        scale_y = 384 / image_height\n",
    "        scale_x = 384 / image_width\n",
    "        chest_y_scaled = int(chest_y_px * scale_y)\n",
    "        chest_x_scaled = int(chest_x * scale_x)\n",
    "        if 0 <= chest_y_scaled < 384 and 0 <= chest_x_scaled < 384:\n",
    "            chest_depth = depth_map[chest_y_scaled, chest_x_scaled]\n",
    "            max_depth = np.max(depth_map)\n",
    "            chest_depth_ratio = 1.0 + 0.5 * (1.0 - chest_depth / max_depth)\n",
    "    \n",
    "    measurements[\"chest_width\"] = pixel_to_cm(chest_width_px)\n",
    "    measurements[\"chest_circumference\"] = calculate_circumference(chest_width_px, chest_depth_ratio)\n",
    "    \n",
    "\n",
    "    # Waist Measurement\n",
    "    left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]\n",
    "    right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value]\n",
    "\n",
    "    # Adjust waist_y_ratio to better reflect the natural waistline\n",
    "    waist_y_ratio = 0.35  # 35% down from shoulder to hip (higher than before)\n",
    "    waist_y = left_shoulder.y + (left_hip.y - left_shoulder.y) * waist_y_ratio\n",
    "\n",
    "    # Use contour detection to dynamically estimate waist width\n",
    "    if frame is not None:\n",
    "        waist_y_px = int(waist_y * image_height)\n",
    "        center_x = (left_hip.x + right_hip.x) / 2\n",
    "        detected_width = get_body_width_at_height(frame, waist_y_px, center_x)\n",
    "        if detected_width > 0:\n",
    "            waist_width_px = detected_width\n",
    "        else:\n",
    "            # Fallback to hip width if contour detection fails\n",
    "            waist_width_px = abs(right_hip.x - left_hip.x) * image_width * 0.9  # 90% of hip width\n",
    "    else:\n",
    "        # Fallback to hip width if no frame is provided\n",
    "        waist_width_px = abs(right_hip.x - left_hip.x) * image_width * 0.9  # 90% of hip width\n",
    "\n",
    "    # Apply 30% correction factor to waist width\n",
    "    waist_correction = 1.16  # 30% wider\n",
    "    waist_width_px *= waist_correction\n",
    "\n",
    "    # Get depth adjustment for waist if available\n",
    "    waist_depth_ratio = 1.0\n",
    "    if depth_map is not None:\n",
    "        waist_x = int(((left_hip.x + right_hip.x) / 2) * image_width)\n",
    "        waist_y_px = int(waist_y * image_height)\n",
    "        scale_y = 384 / image_height\n",
    "        scale_x = 384 / image_width\n",
    "        waist_y_scaled = int(waist_y_px * scale_y)\n",
    "        waist_x_scaled = int(waist_x * scale_x)\n",
    "        if 0 <= waist_y_scaled < 384 and 0 <= waist_x_scaled < 384:\n",
    "            waist_depth = depth_map[waist_y_scaled, waist_x_scaled]\n",
    "            max_depth = np.max(depth_map)\n",
    "            waist_depth_ratio = 1.0 + 0.5 * (1.0 - waist_depth / max_depth)\n",
    "\n",
    "    measurements[\"waist_width\"] = pixel_to_cm(waist_width_px)\n",
    "    measurements[\"waist\"] = calculate_circumference(waist_width_px, waist_depth_ratio)\n",
    "    # Hip Measurement\n",
    "    hip_correction = 1.35  # Hips are typically 35% wider than detected landmarks\n",
    "    hip_width_px = abs(left_hip.x * image_width - right_hip.x * image_width) * hip_correction\n",
    "    \n",
    "    if frame is not None:\n",
    "        hip_y_offset = 0.1  # 10% down from hip landmarks\n",
    "        hip_y = left_hip.y + (landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y - left_hip.y) * hip_y_offset\n",
    "        hip_y_px = int(hip_y * image_height)\n",
    "        center_x = (left_hip.x + right_hip.x) / 2\n",
    "        detected_width = get_body_width_at_height(frame, hip_y_px, center_x)\n",
    "        if detected_width > 0:\n",
    "            hip_width_px = max(hip_width_px, detected_width)\n",
    "    \n",
    "    hip_depth_ratio = 1.0\n",
    "    if depth_map is not None:\n",
    "        hip_x = int(((left_hip.x + right_hip.x) / 2) * image_width)\n",
    "        hip_y_px = int(left_hip.y * image_height)\n",
    "        hip_y_scaled = int(hip_y_px * scale_y)\n",
    "        hip_x_scaled = int(hip_x * scale_x)\n",
    "        if 0 <= hip_y_scaled < 384 and 0 <= hip_x_scaled < 384:\n",
    "            hip_depth = depth_map[hip_y_scaled, hip_x_scaled]\n",
    "            max_depth = np.max(depth_map)\n",
    "            hip_depth_ratio = 1.0 + 0.5 * (1.0 - hip_depth / max_depth)\n",
    "    \n",
    "    measurements[\"hip_width\"] = pixel_to_cm(hip_width_px)\n",
    "    measurements[\"hip\"] = calculate_circumference(hip_width_px, hip_depth_ratio)\n",
    "\n",
    "    # Other measurements (unchanged)\n",
    "    neck = landmarks[mp_pose.PoseLandmark.NOSE.value]\n",
    "    left_ear = landmarks[mp_pose.PoseLandmark.LEFT_EAR.value]\n",
    "    neck_width_px = abs(neck.x * image_width - left_ear.x * image_width) * 2.0\n",
    "    measurements[\"neck\"] = calculate_circumference(neck_width_px, 1.0)\n",
    "    measurements[\"neck_width\"] = pixel_to_cm(neck_width_px)\n",
    "\n",
    "    left_wrist = landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]\n",
    "    sleeve_length_px = abs(left_shoulder.y * image_height - left_wrist.y * image_height)\n",
    "    measurements[\"arm_length\"] = pixel_to_cm(sleeve_length_px)\n",
    "\n",
    "    shirt_length_px = abs(left_shoulder.y * image_height - left_hip.y * image_height) * 1.2\n",
    "    measurements[\"shirt_length\"] = pixel_to_cm(shirt_length_px)\n",
    "\n",
    "     # Thigh Circumference (improved with depth information)\n",
    "    thigh_y_ratio = 0.2  # 20% down from hip to knee\n",
    "    left_knee = landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value]\n",
    "    thigh_y = left_hip.y + (left_knee.y - left_hip.y) * thigh_y_ratio\n",
    "    \n",
    "    # Apply correction factor for thigh width\n",
    "    thigh_correction = 1.2  # Thighs are typically wider than what can be estimated from front view\n",
    "    thigh_width_px = hip_width_px * 0.5 * thigh_correction  # Base thigh width on hip width\n",
    "    \n",
    "    # Use contour detection if frame is available\n",
    "    if frame is not None:\n",
    "        thigh_y_px = int(thigh_y * image_height)\n",
    "        thigh_x = left_hip.x * 0.9  # Move slightly inward from hip\n",
    "        detected_width = get_body_width_at_height(frame, thigh_y_px, thigh_x)\n",
    "        if detected_width > 0 and detected_width < hip_width_px:  # Sanity check\n",
    "            thigh_width_px = detected_width  # Use detected width\n",
    "    \n",
    "    # If depth map is available, use it for thigh measurement\n",
    "    thigh_depth_ratio = 1.0\n",
    "    if depth_map is not None:\n",
    "        thigh_x = int(left_hip.x * image_width)\n",
    "        thigh_y_px = int(thigh_y * image_height)\n",
    "        \n",
    "        # Scale coordinates to match depth map size\n",
    "        thigh_y_scaled = int(thigh_y_px * scale_y)\n",
    "        thigh_x_scaled = int(thigh_x * scale_x)\n",
    "        \n",
    "        if 0 <= thigh_y_scaled < 384 and 0 <= thigh_x_scaled < 384:\n",
    "            thigh_depth = depth_map[thigh_y_scaled, thigh_x_scaled]\n",
    "            max_depth = np.max(depth_map)\n",
    "            thigh_depth_ratio = 1.0 + 0.5 * (1.0 - thigh_depth / max_depth)\n",
    "    \n",
    "    measurements[\"thigh\"] = pixel_to_cm(thigh_width_px)\n",
    "    measurements[\"thigh_circumference\"] = calculate_circumference(thigh_width_px, thigh_depth_ratio)\n",
    "\n",
    "\n",
    "    left_ankle = landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value]\n",
    "    trouser_length_px = abs(left_hip.y * image_height - left_ankle.y * image_height)\n",
    "    measurements[\"trouser_length\"] = pixel_to_cm(trouser_length_px)\n",
    "\n",
    "    return measurements\n",
    "\n",
    "\n",
    "def validate_front_image(image_np):\n",
    "    \"\"\"\n",
    "    Basic validation for front image to ensure:\n",
    "    - There is a person in the image\n",
    "    - Not just a face/selfie (upper body visible)\n",
    "    - Key upper landmarks are detected\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to RGB for MediaPipe\n",
    "        rgb_frame = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "        image_height, image_width = image_np.shape[:2]\n",
    "        \n",
    "        # Process with MediaPipe Holistic\n",
    "        with mp_holistic.Holistic(\n",
    "            static_image_mode=True,\n",
    "            model_complexity=1,\n",
    "            enable_segmentation=False,\n",
    "            refine_face_landmarks=False) as holistic:\n",
    "            \n",
    "            results = holistic.process(rgb_frame)\n",
    "        \n",
    "        if not hasattr(results, 'pose_landmarks') or not results.pose_landmarks:\n",
    "            return False, \"No person detected. Please make sure you're clearly visible in the frame.\"\n",
    "\n",
    "        # Minimum required upper body landmarks\n",
    "        MINIMUM_LANDMARKS = [\n",
    "            mp_holistic.PoseLandmark.NOSE,\n",
    "            mp_holistic.PoseLandmark.LEFT_SHOULDER,\n",
    "            mp_holistic.PoseLandmark.RIGHT_SHOULDER,\n",
    "            mp_holistic.PoseLandmark.LEFT_ELBOW,\n",
    "            mp_holistic.PoseLandmark.RIGHT_ELBOW,\n",
    "            mp_holistic.PoseLandmark.RIGHT_KNEE,\n",
    "            mp_holistic.PoseLandmark.LEFT_KNEE\n",
    "\n",
    "           \n",
    "        ]\n",
    "        \n",
    "        # Verify minimum landmarks are detected\n",
    "        missing_upper = []\n",
    "        for landmark in MINIMUM_LANDMARKS:\n",
    "            landmark_data = results.pose_landmarks.landmark[landmark]\n",
    "            if (landmark_data.visibility < 0.5 or\n",
    "                landmark_data.x < 0 or \n",
    "                landmark_data.x > 1 or\n",
    "                landmark_data.y < 0 or \n",
    "                landmark_data.y > 1):\n",
    "                missing_upper.append(landmark.name.replace('_', ' '))\n",
    "        \n",
    "        if missing_upper:\n",
    "            return False, f\"Couldn't detect full body. Please make sure your full body is visible.\"\n",
    "\n",
    "        # Check if this might be just a face/selfie (no torso)\n",
    "        nose = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE]\n",
    "        left_shoulder = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER]\n",
    "        right_shoulder = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER]\n",
    "        \n",
    "        # Calculate approximate upper body size\n",
    "        shoulder_width = abs(left_shoulder.x - right_shoulder.x) * image_width\n",
    "        head_to_shoulder = abs(left_shoulder.y - nose.y) * image_height\n",
    "        \n",
    "        # If the shoulder width is small compared to head size, likely a selfie\n",
    "        if shoulder_width < head_to_shoulder * 1.2:\n",
    "            return False, \"Please step back to show more of your upper body, not just your face.\"\n",
    "\n",
    "        return True, \"Validation passed - proceeding with measurements\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error validating body image: {e}\")\n",
    "        return False, \"You arent providing images correctly. Please try again.\"\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS  # import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  \n",
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Assume these functions exist\n",
    "# validate_front_image(frame) -> (bool, str)\n",
    "# calculate_distance_using_height(landmarks, image_height, user_height_cm)\n",
    "# detect_reference_object(frame)\n",
    "# estimate_depth(frame)\n",
    "# calculate_measurements(results, scale_factor, image_width, image_height, depth_map, frame, user_height_cm)\n",
    "# extract_size_chart(bytes_data)\n",
    "# find_best_size(measurements, size_chart)\n",
    "# holistic, FOCAL_LENGTH, DEFAULT_HEIGHT_CM\n",
    "\n",
    "@app.route(\"/measurements\", methods=[\"POST\"])\n",
    "def upload_images():\n",
    "    # Read all files once\n",
    "    received_files = {key: request.files[key] for key in [\"front\", \"left_side\", \"size_chart\"] if key in request.files}\n",
    "\n",
    "    if \"front\" not in received_files:\n",
    "        return jsonify({\"error\": \"Missing front image for reference.\"}), 400\n",
    "\n",
    "    # Decode front image\n",
    "    front_bytes = received_files[\"front\"].read()\n",
    "    front_np = np.frombuffer(front_bytes, np.uint8)\n",
    "    front_frame = cv2.imdecode(front_np, cv2.IMREAD_COLOR)\n",
    "\n",
    "    if front_frame is None:\n",
    "        return jsonify({\"error\": \"Front image could not be decoded\"}), 400\n",
    "\n",
    "    # Validate front image\n",
    "    is_valid, error_msg = validate_front_image(front_frame)\n",
    "    if not is_valid:\n",
    "        return jsonify({\n",
    "            \"error\": error_msg,\n",
    "            \"pose\": \"front\",\n",
    "            \"code\": \"INVALID_POSE\"\n",
    "        }), 400\n",
    "\n",
    "    # Get user height\n",
    "    user_height_cm = request.form.get('height_cm', DEFAULT_HEIGHT_CM)\n",
    "    try:\n",
    "        user_height_cm = float(user_height_cm)\n",
    "    except ValueError:\n",
    "        user_height_cm = DEFAULT_HEIGHT_CM\n",
    "\n",
    "    measurements = {}\n",
    "    frames = {}\n",
    "    results = {}\n",
    "    scale_factor = None\n",
    "    focal_length = FOCAL_LENGTH\n",
    "\n",
    "    # Process front and left_side images\n",
    "    for pose_name in [\"front\", \"left_side\"]:\n",
    "        if pose_name not in received_files:\n",
    "            continue\n",
    "\n",
    "        # Reset file pointer for safe reading\n",
    "        received_files[pose_name].seek(0)\n",
    "        img_bytes = received_files[pose_name].read()\n",
    "        frame_np = np.frombuffer(img_bytes, np.uint8)\n",
    "        frame = cv2.imdecode(frame_np, cv2.IMREAD_COLOR)\n",
    "        frames[pose_name] = frame\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results[pose_name] = holistic.process(rgb_frame)\n",
    "        image_height, image_width, _ = frame.shape\n",
    "\n",
    "        if pose_name == \"front\":\n",
    "            if results[pose_name].pose_landmarks:\n",
    "                _, scale_factor = calculate_distance_using_height(\n",
    "                    results[pose_name].pose_landmarks.landmark,\n",
    "                    image_height,\n",
    "                    user_height_cm\n",
    "                )\n",
    "            else:\n",
    "                scale_factor, focal_length = detect_reference_object(frame)\n",
    "\n",
    "        depth_map = estimate_depth(frame) if pose_name in [\"front\", \"left_side\"] else None\n",
    "\n",
    "        if results[pose_name].pose_landmarks and pose_name == \"front\":\n",
    "            measurements.update(calculate_measurements(\n",
    "                results[pose_name],\n",
    "                scale_factor,\n",
    "                image_width,\n",
    "                image_height,\n",
    "                depth_map,\n",
    "                frame,\n",
    "                user_height_cm\n",
    "            ))\n",
    "\n",
    "    # Process size chart\n",
    "    best_size = None\n",
    "    if \"size_chart\" in received_files:\n",
    "        received_files[\"size_chart\"].seek(0)\n",
    "        try:\n",
    "            size_chart_bytes = received_files[\"size_chart\"].read()\n",
    "            size_chart = extract_size_chart(size_chart_bytes)\n",
    "            best_size = find_best_size(measurements, size_chart)\n",
    "        except Exception as e:\n",
    "            print(\"Error processing size chart:\", e)\n",
    "            best_size = None\n",
    "\n",
    "    debug_info = {\n",
    "        \"scale_factor\": float(scale_factor) if scale_factor else None,\n",
    "        \"focal_length\": float(focal_length),\n",
    "        \"user_height_cm\": float(user_height_cm)\n",
    "    }\n",
    "\n",
    "    print(\"Measurements:\", measurements)\n",
    "\n",
    "    return jsonify({\n",
    "        \"measurements\": measurements,\n",
    "        \"best_size\": best_size,\n",
    "        \"debug_info\": debug_info\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8001)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
